{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6/OM50ckpKRVfEG3EkfQN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Toshiya1214/ML-for-automation-of-intracochlear-measurements-of-cochlear-implant-electrode-position-/blob/main/Automating_Intracochlear_Measurements_of_Cochlear_Implant_Electrode_Electrode_Position_through_the_Implementation_of_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7qUFErYzBaw"
      },
      "outputs": [],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yN5iYqqJ5s5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Threshold Segmentation"
      ],
      "metadata": {
        "id": "1pVAwcCB55Ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Read the image\n",
        "image_path = '/Cochlear/0.jpg'\n",
        "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Apply thresholding\n",
        "_, thresholded = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Display the original and thresholded images\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title('Original Image')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(thresholded, cmap='gray')\n",
        "plt.title('Thresholded Image')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ILeDYWjQ50t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Canny Edge Detection Segmentation"
      ],
      "metadata": {
        "id": "xZN_dCJQ5_OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Read the image\n",
        "image_path = '/Cochlear/0.jpg'\n",
        "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Apply Canny edge detection\n",
        "edges = cv2.Canny(image, threshold1=0, threshold2=30)\n",
        "\n",
        "# Display the original image and the edges\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title('Original Image')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(edges, cmap='gray')\n",
        "plt.title('Edges')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v0ZMIUq854ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Windowed Level Segmentation"
      ],
      "metadata": {
        "id": "ATh79xCC6LQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the original medical image\n",
        "original_image = cv2.imread('/Cochlear/0.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Set the desired window level (adjust the values as needed)\n",
        "window_level = -100\n",
        "\n",
        "# Adjust the image pixel values based on the window level\n",
        "windowed_image = cv2.convertScaleAbs(original_image, alpha=1.0, beta=window_level)\n",
        "\n",
        "# Display the images side by side\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(original_image, cmap='gray')\n",
        "plt.title('Original Image')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(windowed_image, cmap='gray')\n",
        "plt.title('Windowed Image (Window Level: {})'.format(window_level))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zeZ692ms6Ktr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Magnitude Segmentation"
      ],
      "metadata": {
        "id": "KK7oesj16clU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the original medical image\n",
        "original_image = cv2.imread('/Cochlear/0.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Check if the image was successfully loaded\n",
        "if original_image is None:\n",
        "    print(\"Failed to load the image.\")\n",
        "else:\n",
        "    # Set the desired window level (adjust the values as needed)\n",
        "    window_level = -100\n",
        "\n",
        "    # Adjust the image pixel values based on the window level\n",
        "    windowed_image = cv2.convertScaleAbs(original_image, alpha=1.0, beta=window_level)\n",
        "\n",
        "    # Apply Gaussian blur to reduce noise (optional)\n",
        "    blurred_image = cv2.GaussianBlur(windowed_image, (5, 5), 0)\n",
        "\n",
        "    # Calculate gradients using the Sobel operator\n",
        "    gradient_x = cv2.Sobel(blurred_image, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    gradient_y = cv2.Sobel(blurred_image, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "    # Calculate the gradient magnitude\n",
        "    gradient_magnitude = np.sqrt(gradient_x ** 2 + gradient_y ** 2)\n",
        "\n",
        "    # Normalize the gradient magnitude to 0-255\n",
        "    gradient_magnitude = cv2.normalize(gradient_magnitude, None, 250,270, cv2.NORM_MINMAX, cv2.CV_8U)\n",
        "\n",
        "    # Display the images side by side\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(windowed_image, cmap='gray')\n",
        "    plt.title('windowed_image')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(gradient_magnitude, cmap='gray')\n",
        "    plt.title('Gradient Magnitude')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "XDN1lyFI6cFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Windowed Level Segmentation VS Threshold Segmentation"
      ],
      "metadata": {
        "id": "UJilz0KA6mSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the original medical image\n",
        "original_image = cv2.imread('/Cochlear/0.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Set the desired window level (adjust the values as needed)\n",
        "window_level = -100\n",
        "\n",
        "# Adjust the image pixel values based on the window level\n",
        "windowed_image = cv2.convertScaleAbs(original_image, alpha=1.0, beta=window_level)\n",
        "\n",
        "# Apply thresholding\n",
        "_, thresholded = cv2.threshold(windowed_image, 40, 400, cv2.THRESH_BINARY)\n",
        "\n",
        "# Display the images side by side\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(windowed_image, cmap='gray')\n",
        "plt.title('Windowed Image (Window Level: {})'.format(window_level))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(thresholded, cmap='gray')\n",
        "plt.title('Thresholded Image')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J0S5tORr6lu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAM (Segment Anything Model)"
      ],
      "metadata": {
        "id": "xNoZWr5t6yAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "5wfKkPkG6wUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ],
      "metadata": {
        "id": "xdxMpRQs64mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'"
      ],
      "metadata": {
        "id": "B5CtPPdu68HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision"
      ],
      "metadata": {
        "id": "wzTXlIjF6-aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!mkdir {HOME}/weights\n",
        "%cd {HOME}/weights\n",
        "\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ],
      "metadata": {
        "id": "q92F4Dp_6_-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
        "print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))"
      ],
      "metadata": {
        "id": "OJ9owsSz7CAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_TYPE = \"vit_h\""
      ],
      "metadata": {
        "id": "VSJHk-JF7Do7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)"
      ],
      "metadata": {
        "id": "jOUrfJsh7FjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_generator = SamAutomaticMaskGenerator(sam)"
      ],
      "metadata": {
        "id": "uGfxHBjp7JRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "IMAGE_NAME = \"/Cochlear/0.jpg\"\n",
        "IMAGE_PATH = os.path.join(HOME, \"data\", IMAGE_NAME)"
      ],
      "metadata": {
        "id": "Dd7Hv8C47Jyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import supervision as sv\n",
        "\n",
        "image_bgr = cv2.imread(IMAGE_PATH)\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "sam_result = mask_generator.generate(image_rgb)"
      ],
      "metadata": {
        "id": "MarX-h_d7Laa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sam_result[0].keys())"
      ],
      "metadata": {
        "id": "WuZfLZKe7MrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_annotator = sv.MaskAnnotator()\n",
        "\n",
        "detections = sv.Detections.from_sam(sam_result=sam_result)\n",
        "\n",
        "annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=[image_bgr, annotated_image],\n",
        "    grid_size=(1, 2),\n",
        "    titles=['source image', 'segmented image']\n",
        ")"
      ],
      "metadata": {
        "id": "KVpo9DHI7PZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAM Generate Segmentation with Bounding Box"
      ],
      "metadata": {
        "id": "ffhoTqTH7S4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask_predictor = SamPredictor(sam)"
      ],
      "metadata": {
        "id": "gAL6sI787VtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "IMAGE_NAME = \"/Cochlear/0.jpg\"\n",
        "IMAGE_PATH = os.path.join(HOME, \"data\", IMAGE_NAME)"
      ],
      "metadata": {
        "id": "2D0mhN687doe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function that loads an image before adding it to the widget\n",
        "\n",
        "import base64\n",
        "\n",
        "def encode_image(filepath):\n",
        "    with open(filepath, 'rb') as f:\n",
        "        image_bytes = f.read()\n",
        "    encoded = str(base64.b64encode(image_bytes), 'utf-8')\n",
        "    return \"data:image/jpg;base64,\"+encoded"
      ],
      "metadata": {
        "id": "qI6temrB7fG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_COLAB = True\n",
        "\n",
        "if IS_COLAB:\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()\n",
        "\n",
        "from jupyter_bbox_widget import BBoxWidget\n",
        "\n",
        "widget = BBoxWidget()\n",
        "widget.image = encode_image(IMAGE_PATH)\n",
        "widget"
      ],
      "metadata": {
        "id": "Kj5oyQ4w7ggB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "widget.bboxes"
      ],
      "metadata": {
        "id": "planG8wG7h_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# default_box is going to be used if you will not draw any box on image above\n",
        "default_box = {'x': 68, 'y': 247, 'width': 555, 'height': 678, 'label': ''}\n",
        "\n",
        "box = widget.bboxes[0] if widget.bboxes else default_box\n",
        "box = np.array([\n",
        "    box['x'],\n",
        "    box['y'],\n",
        "    box['x'] + box['width'],\n",
        "    box['y'] + box['height']\n",
        "])"
      ],
      "metadata": {
        "id": "6ilKUvSJ7jwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "image_bgr = cv2.imread(IMAGE_PATH)\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "mask_predictor.set_image(image_rgb)\n",
        "\n",
        "masks, scores, logits = mask_predictor.predict(\n",
        "    box=box,\n",
        "    multimask_output=True\n",
        ")"
      ],
      "metadata": {
        "id": "CO2dn3z67mAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "box_annotator = sv.BoxAnnotator(color=sv.Color.red())\n",
        "mask_annotator = sv.MaskAnnotator(color=sv.Color.red())\n",
        "\n",
        "detections = sv.Detections(\n",
        "    xyxy=sv.mask_to_xyxy(masks=masks),\n",
        "    mask=masks\n",
        ")\n",
        "detections = detections[detections.area == np.max(detections.area)]\n",
        "\n",
        "source_image = box_annotator.annotate(scene=image_bgr.copy(), detections=detections, skip_label=True)\n",
        "segmented_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=[source_image, segmented_image],\n",
        "    grid_size=(1, 2),\n",
        "    titles=['source image', 'segmented image']\n",
        ")"
      ],
      "metadata": {
        "id": "cC3ZIYix7mjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN (Convolutional Neutal Network) model Epochs = 10"
      ],
      "metadata": {
        "id": "2lI2Pha7774q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mtWJn-Sx765d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the paths to the directories containing the data\n",
        "labeled_image_dir = '/content/drive/MyDrive/CochlearPP42'  # Replace with the actual path\n",
        "csv_dir = '/content/drive/MyDrive/CochlearCSV42'  # Replace with the actual path\n",
        "\n",
        "# Preprocessing parameters\n",
        "image_size = (224, 224)  # Size of the resized images\n",
        "\n",
        "# Lists to store the preprocessed data\n",
        "preprocessed_images = []\n",
        "normalized_coordinates = []\n",
        "\n",
        "# Loop over each labeled image and corresponding CSV file\n",
        "for image_index in range(50):\n",
        "    # Load the labeled image if it exists\n",
        "    labeled_image_path = os.path.join(labeled_image_dir, f'{image_index:03d}.jpg')\n",
        "    if not os.path.isfile(labeled_image_path):\n",
        "        print(f\"Labeled image {labeled_image_path} not found. Skipping image {image_index}.\")\n",
        "        continue\n",
        "\n",
        "    labeled_image = cv2.imread(labeled_image_path)\n",
        "    labeled_image = cv2.resize(labeled_image, image_size)\n",
        "    preprocessed_images.append(labeled_image)\n",
        "\n",
        "    # Load the corresponding CSV file if it exists\n",
        "    csv_path = os.path.join(csv_dir, f'{image_index:03d}.csv')\n",
        "    if not os.path.isfile(csv_path):\n",
        "        print(f\"CSV file {csv_path} not found. Skipping image {image_index}.\")\n",
        "        preprocessed_images.pop()  # Remove the corresponding labeled image\n",
        "        continue\n",
        "\n",
        "    coordinates_df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Extract the (x, y) coordinates from the CSV\n",
        "    coordinates = coordinates_df[['x', 'y']].values\n",
        "\n",
        "    # Normalize the coordinates\n",
        "    normalized_coordinates.append(coordinates)  # Add to the list\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "preprocessed_images = np.array(preprocessed_images)\n",
        "normalized_coordinates = np.array(normalized_coordinates)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "train_images = preprocessed_images[9:]\n",
        "train_coordinates = normalized_coordinates[9:]\n",
        "\n",
        "val_images = preprocessed_images[:9]\n",
        "val_coordinates = normalized_coordinates[:9]\n",
        "\n",
        "\n",
        "# Proceed with model training using the preprocessed data\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define your CNN model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10*2)  # 20 output units for 10 points (x, y) coordinates\n",
        "])\n",
        "\n",
        "# Reshape the target coordinates to match the model's output\n",
        "train_coordinates_reshaped = train_coordinates.reshape(-1, 10 * 2)\n",
        "val_coordinates_reshaped = val_coordinates.reshape(-1, 10 * 2)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_coordinates_reshaped, epochs=10, validation_data=(val_images, val_coordinates_reshaped))\n"
      ],
      "metadata": {
        "id": "WBqFsR078EUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the training and validation loss values from the history\n",
        "training_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "\n",
        "# Plot the training and validation loss\n",
        "epochs = range(1, len(training_loss) + 1)\n",
        "\n",
        "plt.plot(epochs, training_loss, 'bo-', label='Training Loss')\n",
        "plt.plot(epochs, validation_loss, 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0IR2dSLC8EAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss = model.evaluate(val_images, val_coordinates_reshaped)\n",
        "print(\"Test loss:\", test_loss)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(val_images)\n",
        "# Reshape the predictions and true coordinates\n",
        "predictions_reshaped = predictions.reshape(-1, 10 * 2)\n",
        "# Calculate the mean squared error (MSE)\n",
        "mse = mean_squared_error(val_coordinates_reshaped, predictions_reshaped)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "# Calculate the mean absolute error (MAE)\n",
        "mae = mean_absolute_error(val_coordinates_reshaped, predictions_reshaped)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "# Calculate the R2 score\n",
        "r2 = r2_score(val_coordinates_reshaped, predictions_reshaped)\n",
        "print(\"R2 Score:\", r2)\n",
        "\n",
        "from sklearn.metrics import explained_variance_score\n",
        "# Calculate the explained variance score\n",
        "explained_variance = explained_variance_score(val_coordinates_reshaped, predictions_reshaped)\n",
        "print(\"Explained Variance Score:\", explained_variance)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(val_coordinates_reshaped, predictions_reshaped))\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "# Calculate MAPE\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    epsilon = 1e-10  # small constant to avoid division by zero\n",
        "    return np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100\n",
        "\n",
        "mape = mean_absolute_percentage_error(val_coordinates_reshaped, predictions_reshaped)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
      ],
      "metadata": {
        "id": "sk6Dh4Yp8R2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN (Convolutional Neutal Network) model Epochs = 100"
      ],
      "metadata": {
        "id": "HVKzhIHH82SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the paths to the directories containing the data\n",
        "labeled_image_dir = '/content/drive/MyDrive/CochlearPP42'  # Replace with the actual path\n",
        "csv_dir = '/content/drive/MyDrive/CochlearCSV42'  # Replace with the actual path\n",
        "\n",
        "# Preprocessing parameters\n",
        "image_size = (224, 224)  # Size of the resized images\n",
        "\n",
        "# Lists to store the preprocessed data\n",
        "preprocessed_images = []\n",
        "normalized_coordinates = []\n",
        "\n",
        "# Loop over each labeled image and corresponding CSV file\n",
        "for image_index in range(50):\n",
        "    # Load the labeled image if it exists\n",
        "    labeled_image_path = os.path.join(labeled_image_dir, f'{image_index:03d}.jpg')\n",
        "    if not os.path.isfile(labeled_image_path):\n",
        "        print(f\"Labeled image {labeled_image_path} not found. Skipping image {image_index}.\")\n",
        "        continue\n",
        "\n",
        "    labeled_image = cv2.imread(labeled_image_path)\n",
        "    labeled_image = cv2.resize(labeled_image, image_size)\n",
        "    preprocessed_images.append(labeled_image)\n",
        "\n",
        "    # Load the corresponding CSV file if it exists\n",
        "    csv_path = os.path.join(csv_dir, f'{image_index:03d}.csv')\n",
        "    if not os.path.isfile(csv_path):\n",
        "        print(f\"CSV file {csv_path} not found. Skipping image {image_index}.\")\n",
        "        preprocessed_images.pop()  # Remove the corresponding labeled image\n",
        "        continue\n",
        "\n",
        "    coordinates_df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Extract the (x, y) coordinates from the CSV\n",
        "    coordinates = coordinates_df[['x', 'y']].values\n",
        "\n",
        "    # Normalize the coordinates\n",
        "    normalized_coordinates.append(coordinates)  # Add to the list\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "preprocessed_images = np.array(preprocessed_images)\n",
        "normalized_coordinates = np.array(normalized_coordinates)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "train_images = preprocessed_images[9:]\n",
        "train_coordinates = normalized_coordinates[9:]\n",
        "\n",
        "val_images = preprocessed_images[:9]\n",
        "val_coordinates = normalized_coordinates[:9]\n",
        "\n",
        "\n",
        "# Proceed with model training using the preprocessed data\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define your CNN model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10*2)  # 20 output units for 10 points (x, y) coordinates\n",
        "])\n",
        "\n",
        "# Reshape the target coordinates to match the model's output\n",
        "train_coordinates_reshaped = train_coordinates.reshape(-1, 10 * 2)\n",
        "val_coordinates_reshaped = val_coordinates.reshape(-1, 10 * 2)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_coordinates_reshaped, epochs=100, validation_data=(val_images, val_coordinates_reshaped))"
      ],
      "metadata": {
        "id": "EVtosTa780gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the training and validation loss values from the history\n",
        "training_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "\n",
        "# Plot the training and validation loss\n",
        "epochs = range(1, len(training_loss) + 1)\n",
        "\n",
        "plt.plot(epochs, training_loss, 'bo-', label='Training Loss')\n",
        "plt.plot(epochs, validation_loss, 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v9HGzyqG87Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss = model.evaluate(val_images, val_coordinates_reshaped)\n",
        "print(\"Test loss:\", test_loss)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(val_images)\n",
        "# Reshape the predictions and true coordinates\n",
        "predictions_reshaped = predictions.reshape(-1, 10 * 2)\n",
        "# Calculate the mean squared error (MSE)\n",
        "mse = mean_squared_error(val_coordinates_reshaped, predictions_reshaped)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "# Calculate the mean absolute error (MAE)\n",
        "mae = mean_absolute_error(val_coordinates_reshaped, predictions_reshaped)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "# Calculate the R2 score\n",
        "r2 = r2_score(val_coordinates_reshaped, predictions_reshaped)\n",
        "print(\"R2 Score:\", r2)\n",
        "\n",
        "from sklearn.metrics import explained_variance_score\n",
        "# Calculate the explained variance score\n",
        "explained_variance = explained_variance_score(val_coordinates_reshaped, predictions_reshaped)\n",
        "print(\"Explained Variance Score:\", explained_variance)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(val_coordinates_reshaped, predictions_reshaped))\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "# Calculate MAPE\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    epsilon = 1e-10  # small constant to avoid division by zero\n",
        "    return np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100\n",
        "\n",
        "mape = mean_absolute_percentage_error(val_coordinates_reshaped, predictions_reshaped)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
      ],
      "metadata": {
        "id": "hiq32dF889T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export Prediction values"
      ],
      "metadata": {
        "id": "N4gVaoSj9ZYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the labels for each point\n",
        "labels = ['point1', 'point2', 'LW4', 'E4', 'E2', 'LW2', 'LW1', 'E1', 'E3', 'LW3']\n",
        "\n",
        "# Loop over each image and its corresponding predicted coordinates\n",
        "for i, coordinates in enumerate(predictions):\n",
        "    # Reshape the coordinates array\n",
        "    coordinates = coordinates.reshape(10, 2)\n",
        "\n",
        "    # Create a DataFrame with the coordinates and labels\n",
        "    df = pd.DataFrame({'Label': labels, 'x': coordinates[:, 0], 'y': coordinates[:, 1]})\n",
        "\n",
        "    # Define the output path for the CSV file\n",
        "    output_path = f'/content/drive/MyDrive/CochlearCNNXY/{i}.csv'\n",
        "\n",
        "    # Export the DataFrame as a CSV file\n",
        "    df.to_csv(output_path, index=False)"
      ],
      "metadata": {
        "id": "BPbe6SLH9ZK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Get a list of all CSV files in the directory\n",
        "csv_files = glob.glob('/content/drive/MyDrive/CochlearCNNXY/*.csv')\n",
        "\n",
        "# Define a function to calculate the distance between two points\n",
        "def calculate_distance(x1, y1, x2, y2):\n",
        "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
        "\n",
        "# Create an empty DataFrame to store the results\n",
        "results = pd.DataFrame(columns=['SID', 'DL1', 'DL2', 'DL3', 'DL4', 'DE1', 'DE2', 'DE3', 'DE4'])\n",
        "\n",
        "# Iterate over each CSV file\n",
        "for file in csv_files:\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file)\n",
        "\n",
        "    # Get the file name without the directory and extension\n",
        "    file_name = os.path.splitext(os.path.basename(file))[0]\n",
        "    file_name = f\"{file_name}.jpg\"  # Add .jpg extension\n",
        "\n",
        "    # Get the coordinates of Point 2\n",
        "    point2_row = df[df['Label'] == 'point2']\n",
        "    point2_x = point2_row['x'].values[0]\n",
        "    point2_y = point2_row['y'].values[0]\n",
        "\n",
        "    # Calculate distances between Point 2 and other labeled points\n",
        "    distances = {}\n",
        "\n",
        "    label_mapping = {\n",
        "        'LW1': 'DL1',\n",
        "        'LW2': 'DL2',\n",
        "        'LW3': 'DL3',\n",
        "        'LW4': 'DL4',\n",
        "        'E1': 'DE1',\n",
        "        'E2': 'DE2',\n",
        "        'E3': 'DE3',\n",
        "        'E4': 'DE4'\n",
        "    }\n",
        "\n",
        "    for label, new_label in label_mapping.items():\n",
        "        row = df[df['Label'] == label]\n",
        "        x = row['x'].values[0]\n",
        "        y = row['y'].values[0]\n",
        "        distance = calculate_distance(point2_x, point2_y, x, y)\n",
        "        distances[new_label] = distance\n",
        "\n",
        "    # Create a new DataFrame with the results for the current file\n",
        "    file_results = pd.DataFrame([distances], index=[file_name])\n",
        "\n",
        "    # Append the file results to the overall results DataFrame\n",
        "    results = pd.concat([results, file_results])\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results.to_csv('/content/drive/MyDrive/CochlearDistance42/CNNPreD.csv', float_format='%.2f')"
      ],
      "metadata": {
        "id": "gTJp_6lN9hlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Conversion Factors from Preficted values and Actual value\\s"
      ],
      "metadata": {
        "id": "-yFfJSqj91Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the average conversion factors\n",
        "conversion_factors = {\n",
        "    'DL1': 0.009903744900565298,\n",
        "    'DL2': 0.011548086674706151,\n",
        "    'DL3': 0.011543324708090776,\n",
        "    'DL4': 0.009351584017787348,\n",
        "    'DE1': 0.009561528996987883,\n",
        "    'DE2': 0.011767608791001308,\n",
        "    'DE3': 0.0117744825198021,\n",
        "    'DE4': 0.009391603290466594\n",
        "}\n",
        "\n",
        "# Read the CSV file with distance values\n",
        "df = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/CNNPreD42.csv')\n",
        "\n",
        "# Loop over the columns (distance labels)\n",
        "for column in df.columns[2:]:\n",
        "    # Get the conversion factor for the current label\n",
        "    conversion_factor = conversion_factors[column]\n",
        "\n",
        "    # Convert the distance values to millimeters\n",
        "    df[column] = df[column] * conversion_factor\n",
        "\n",
        "# Save the converted distances to a new CSV file\n",
        "df.to_csv('/content/drive/MyDrive/CochlearDistance42/CNNPreD_mm42.csv', index=False, float_format='%.2f')\n"
      ],
      "metadata": {
        "id": "h-C_iL6f9iak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Read the CSV file with the actual distance values in millimeters\n",
        "actual_distances_df = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/CochlearDMM42.csv')\n",
        "\n",
        "# Read the CSV file with the newly generated millimeter values\n",
        "calculated_distances_mm_df = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/CNNPreD_mm42.csv')\n",
        "\n",
        "# Get the columns to evaluate\n",
        "columns_to_evaluate = ['DL1', 'DL2', 'DL3', 'DL4', 'DE1', 'DE2', 'DE3', 'DE4']\n",
        "\n",
        "# Calculate the mean absolute error for each column\n",
        "mae_scores = {}\n",
        "for column in columns_to_evaluate:\n",
        "    # Select the first 8 rows from the actual and calculated distances dataframes\n",
        "    actual_distances = actual_distances_df[column][:8]\n",
        "    calculated_distances = calculated_distances_mm_df[column][:8]\n",
        "\n",
        "    # Calculate the mean absolute error\n",
        "    mae = mean_absolute_error(actual_distances, calculated_distances)\n",
        "    mae_scores[column] = mae\n",
        "\n",
        "# Print the mean absolute error for each column\n",
        "for column, mae in mae_scores.items():\n",
        "    print(f\"Mean Absolute Error for {column}: {mae}\")\n"
      ],
      "metadata": {
        "id": "ktPsDK719mtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet-50 (Residual Neural Network 50 layers)  model Epochs=10"
      ],
      "metadata": {
        "id": "F-d_Bmd5-UZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "# Define the paths to the directories containing the data\n",
        "labeled_image_dir = '/content/drive/MyDrive/CochlearPP42'  # Replace with the actual path\n",
        "csv_dir = '/content/drive/MyDrive/CochlearCSV42'  # Replace with the actual path\n",
        "\n",
        "# Preprocessing parameters\n",
        "image_size = (224, 224)  # Size of the resized images\n",
        "\n",
        "# Lists to store the preprocessed data\n",
        "preprocessed_images = []\n",
        "normalized_coordinates = []\n",
        "\n",
        "# Loop over each labeled image and corresponding CSV file\n",
        "for image_index in range(50):\n",
        "    # Load the labeled image\n",
        "    labeled_image_path = os.path.join(labeled_image_dir, f'{image_index:03d}.jpg')\n",
        "    if not os.path.isfile(labeled_image_path):\n",
        "        print(f\"Labeled image {labeled_image_path} not found. Skipping image {image_index}.\")\n",
        "        continue\n",
        "\n",
        "    labeled_image = cv2.imread(labeled_image_path)\n",
        "    labeled_image = cv2.resize(labeled_image, image_size)\n",
        "    preprocessed_images.append(labeled_image)\n",
        "\n",
        "    # Load the corresponding CSV file if it exists\n",
        "    csv_path = os.path.join(csv_dir, f'{image_index:03d}.csv')\n",
        "    if not os.path.isfile(csv_path):\n",
        "        print(f\"CSV file {csv_path} not found. Skipping image {image_index}.\")\n",
        "        preprocessed_images.pop()  # Remove the corresponding labeled image\n",
        "        continue\n",
        "\n",
        "    coordinates_df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Extract the (x, y) coordinates from the CSV\n",
        "    coordinates = coordinates_df[['x', 'y']].values\n",
        "\n",
        "    # Normalize the coordinates\n",
        "    normalized_coordinates.append(coordinates)  # Add to the list\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "preprocessed_images = np.array(preprocessed_images)\n",
        "normalized_coordinates = np.array(normalized_coordinates)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "train_images = preprocessed_images[9:]\n",
        "train_coordinates = normalized_coordinates[9:]\n",
        "\n",
        "val_images = preprocessed_images[:9]\n",
        "val_coordinates = normalized_coordinates[:9]\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "# Load the pre-trained ResNet-50 model\n",
        "model = resnet50(pretrained=True)\n",
        "\n",
        "# Modify the model's last layer for regression\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 10 * 2)  # 10 points (x, y) coordinates per sample\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "train_images_tensor = torch.from_numpy(train_images).permute(0, 3, 1, 2).float()\n",
        "train_coordinates_tensor = torch.from_numpy(train_coordinates).float()\n",
        "\n",
        "val_images_tensor = torch.from_numpy(val_images).permute(0, 3, 1, 2).float()\n",
        "val_coordinates_tensor = torch.from_numpy(val_coordinates).float()\n",
        "\n",
        "# Reshape the target tensors\n",
        "train_coordinates_tensor = train_coordinates_tensor.view(-1, 10 * 2)\n",
        "val_coordinates_tensor = val_coordinates_tensor.view(-1, 10 * 2)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "batch_size = 8\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Lists to store the training and validation loss\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i in range(0, len(train_images), batch_size):\n",
        "        # Prepare batch\n",
        "        batch_images = train_images_tensor[i:i + batch_size]\n",
        "        batch_coordinates = train_coordinates_tensor[i:i + batch_size]\n",
        "\n",
        "        # Forward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_images)\n",
        "        loss = loss_fn(outputs, batch_coordinates)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluation on the validation set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(val_images_tensor)\n",
        "        val_loss = loss_fn(val_outputs, val_coordinates_tensor)\n",
        "\n",
        "    # Append the training and validation loss to the history\n",
        "    train_loss_history.append(loss.item())\n",
        "    val_loss_history.append(val_loss.item())\n",
        "\n",
        "    # Print the progress\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "    if epoch == num_epochs - 1:\n",
        "        # Plot the training and validation loss for the last epoch\n",
        "        epochs = range(1, epoch + 2)\n",
        "        plt.plot(epochs, train_loss_history, 'bo-', label='Training Loss')\n",
        "        plt.plot(epochs, val_loss_history, 'ro-', label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "nul9Piyb-Pj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Calculate predictions for the validation set\n",
        "val_predictions = model(val_images_tensor)\n",
        "\n",
        "# Detach the tensors from the computation graph and convert to NumPy arrays\n",
        "val_coordinates_numpy = val_coordinates_tensor.detach().numpy()\n",
        "val_predictions_numpy = val_predictions.detach().numpy()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "val_loss = loss_fn(val_predictions, val_coordinates_tensor)\n",
        "mse_val = mean_squared_error(val_coordinates_numpy, val_predictions_numpy)\n",
        "mae_val = mean_absolute_error(val_coordinates_numpy, val_predictions_numpy)\n",
        "r2_val = r2_score(val_coordinates_numpy, val_predictions_numpy)\n",
        "explained_variance_val = explained_variance_score(val_coordinates_numpy, val_predictions_numpy)\n",
        "rmse_val = math.sqrt(mse_val)\n",
        "\n",
        "# Calculate MAPE if there are no zero values in val_coordinates_numpy\n",
        "if np.any(val_coordinates_numpy == 0):\n",
        "    mape_val = np.inf\n",
        "else:\n",
        "    mape_val = np.mean(np.abs((val_coordinates_numpy - val_predictions_numpy) / val_coordinates_numpy)) * 100\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"MSE: {mse_val:.4f}\")\n",
        "print(f\"MAE: {mae_val:.4f}\")\n",
        "print(f\"R2: {r2_val:.4f}\")\n",
        "print(f\"Explained Variance Score: {explained_variance_val:.4f}\")\n",
        "print(f\"RMSE: {rmse_val:.4f}\")\n",
        "print(f\"MAPE: {mape_val:.4f}%\")"
      ],
      "metadata": {
        "id": "B7NEFYSA-pSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet-50 (Residual Neural Network 50 layers)  model Epochs=100"
      ],
      "metadata": {
        "id": "5sXi9P6R-vu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "# Define the paths to the directories containing the data\n",
        "labeled_image_dir = '/content/drive/MyDrive/CochlearPP42'  # Replace with the actual path\n",
        "csv_dir = '/content/drive/MyDrive/CochlearCSV42'  # Replace with the actual path\n",
        "\n",
        "# Preprocessing parameters\n",
        "image_size = (224, 224)  # Size of the resized images\n",
        "\n",
        "# Lists to store the preprocessed data\n",
        "preprocessed_images = []\n",
        "normalized_coordinates = []\n",
        "\n",
        "# Loop over each labeled image and corresponding CSV file\n",
        "for image_index in range(50):\n",
        "    # Load the labeled image\n",
        "    labeled_image_path = os.path.join(labeled_image_dir, f'{image_index:03d}.jpg')\n",
        "    if not os.path.isfile(labeled_image_path):\n",
        "        print(f\"Labeled image {labeled_image_path} not found. Skipping image {image_index}.\")\n",
        "        continue\n",
        "\n",
        "    labeled_image = cv2.imread(labeled_image_path)\n",
        "    labeled_image = cv2.resize(labeled_image, image_size)\n",
        "    preprocessed_images.append(labeled_image)\n",
        "\n",
        "    # Load the corresponding CSV file if it exists\n",
        "    csv_path = os.path.join(csv_dir, f'{image_index:03d}.csv')\n",
        "    if not os.path.isfile(csv_path):\n",
        "        print(f\"CSV file {csv_path} not found. Skipping image {image_index}.\")\n",
        "        preprocessed_images.pop()  # Remove the corresponding labeled image\n",
        "        continue\n",
        "\n",
        "    coordinates_df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Extract the (x, y) coordinates from the CSV\n",
        "    coordinates = coordinates_df[['x', 'y']].values\n",
        "\n",
        "    # Normalize the coordinates\n",
        "    normalized_coordinates.append(coordinates)  # Add to the list\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "preprocessed_images = np.array(preprocessed_images)\n",
        "normalized_coordinates = np.array(normalized_coordinates)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "train_images = preprocessed_images[9:]\n",
        "train_coordinates = normalized_coordinates[9:]\n",
        "\n",
        "val_images = preprocessed_images[:9]\n",
        "val_coordinates = normalized_coordinates[:9]\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "# Load the pre-trained ResNet-50 model\n",
        "model = resnet50(pretrained=True)\n",
        "\n",
        "# Modify the model's last layer for regression\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 10 * 2)  # 10 points (x, y) coordinates per sample\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "train_images_tensor = torch.from_numpy(train_images).permute(0, 3, 1, 2).float()\n",
        "train_coordinates_tensor = torch.from_numpy(train_coordinates).float()\n",
        "\n",
        "val_images_tensor = torch.from_numpy(val_images).permute(0, 3, 1, 2).float()\n",
        "val_coordinates_tensor = torch.from_numpy(val_coordinates).float()\n",
        "\n",
        "# Reshape the target tensors\n",
        "train_coordinates_tensor = train_coordinates_tensor.view(-1, 10 * 2)\n",
        "val_coordinates_tensor = val_coordinates_tensor.view(-1, 10 * 2)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 100\n",
        "batch_size = 8\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Lists to store the training and validation loss\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i in range(0, len(train_images), batch_size):\n",
        "        # Prepare batch\n",
        "        batch_images = train_images_tensor[i:i + batch_size]\n",
        "        batch_coordinates = train_coordinates_tensor[i:i + batch_size]\n",
        "\n",
        "        # Forward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_images)\n",
        "        loss = loss_fn(outputs, batch_coordinates)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluation on the validation set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(val_images_tensor)\n",
        "        val_loss = loss_fn(val_outputs, val_coordinates_tensor)\n",
        "\n",
        "    # Append the training and validation loss to the history\n",
        "    train_loss_history.append(loss.item())\n",
        "    val_loss_history.append(val_loss.item())\n",
        "\n",
        "    # Print the progress\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "    if epoch == num_epochs - 1:\n",
        "        # Plot the training and validation loss for the last epoch\n",
        "        epochs = range(1, epoch + 2)\n",
        "        plt.plot(epochs, train_loss_history, 'bo-', label='Training Loss')\n",
        "        plt.plot(epochs, val_loss_history, 'ro-', label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "G0MQX_Lp-r_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Calculate predictions for the validation set\n",
        "val_predictions = model(val_images_tensor)\n",
        "\n",
        "# Detach the tensors from the computation graph and convert to NumPy arrays\n",
        "val_coordinates_numpy = val_coordinates_tensor.detach().numpy()\n",
        "val_predictions_numpy = val_predictions.detach().numpy()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "val_loss = loss_fn(val_predictions, val_coordinates_tensor)\n",
        "mse_val = mean_squared_error(val_coordinates_numpy, val_predictions_numpy)\n",
        "mae_val = mean_absolute_error(val_coordinates_numpy, val_predictions_numpy)\n",
        "r2_val = r2_score(val_coordinates_numpy, val_predictions_numpy)\n",
        "explained_variance_val = explained_variance_score(val_coordinates_numpy, val_predictions_numpy)\n",
        "rmse_val = math.sqrt(mse_val)\n",
        "\n",
        "# Calculate MAPE if there are no zero values in val_coordinates_numpy\n",
        "if np.any(val_coordinates_numpy == 0):\n",
        "    mape_val = np.inf\n",
        "else:\n",
        "    mape_val = np.mean(np.abs((val_coordinates_numpy - val_predictions_numpy) / val_coordinates_numpy)) * 100\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"MSE: {mse_val:.4f}\")\n",
        "print(f\"MAE: {mae_val:.4f}\")\n",
        "print(f\"R2: {r2_val:.4f}\")\n",
        "print(f\"Explained Variance Score: {explained_variance_val:.4f}\")\n",
        "print(f\"RMSE: {rmse_val:.4f}\")\n",
        "print(f\"MAPE: {mape_val:.4f}%\")"
      ],
      "metadata": {
        "id": "LpGzTfbv-xkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expoert Prediction values"
      ],
      "metadata": {
        "id": "27Z246GS_V2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the labels for each point\n",
        "labels = ['point1', 'point2', 'LW4', 'E4', 'E2', 'LW2', 'LW1', 'E1', 'E3', 'LW3']\n",
        "\n",
        "# Loop over each image and its corresponding predicted coordinates\n",
        "for i, coordinates in enumerate(predicted_coordinates):\n",
        "    # Create a DataFrame with the coordinates and labels\n",
        "    df = pd.DataFrame({'Label': labels, 'x': coordinates[:, 0], 'y': coordinates[:, 1]})\n",
        "\n",
        "    # Define the output path for the CSV file\n",
        "    output_path = f'/content/drive/MyDrive/CochlearResNetXY/{i}.csv'\n",
        "\n",
        "    # Export the DataFrame as a CSV file\n",
        "    df.to_csv(output_path, index=False)"
      ],
      "metadata": {
        "id": "ACmgs_WO_Wx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Get a list of all CSV files in the directory\n",
        "csv_files = glob.glob('/content/drive/MyDrive/CochlearResNetXY/*.csv')\n",
        "\n",
        "# Define a function to calculate the distance between two points\n",
        "def calculate_distance(x1, y1, x2, y2):\n",
        "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
        "\n",
        "# Create an empty DataFrame to store the results\n",
        "results = pd.DataFrame(columns=['SID', 'DL1', 'DL2', 'DL3', 'DL4', 'DE1', 'DE2', 'DE3', 'DE4'])\n",
        "\n",
        "# Iterate over each CSV file\n",
        "for file in csv_files:\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file)\n",
        "\n",
        "    # Get the file name without the directory and extension\n",
        "    file_name = os.path.splitext(os.path.basename(file))[0]\n",
        "    file_name = f\"{file_name}.jpg\"  # Add .jpg extension\n",
        "\n",
        "    # Get the coordinates of Point 2\n",
        "    point2_row = df[df['Label'] == 'point2']\n",
        "    point2_x = point2_row['x'].values[0]\n",
        "    point2_y = point2_row['y'].values[0]\n",
        "\n",
        "    # Calculate distances between Point 2 and other labeled points\n",
        "    distances = {}\n",
        "\n",
        "    label_mapping = {\n",
        "        'LW1': 'DL1',\n",
        "        'LW2': 'DL2',\n",
        "        'LW3': 'DL3',\n",
        "        'LW4': 'DL4',\n",
        "        'E1': 'DE1',\n",
        "        'E2': 'DE2',\n",
        "        'E3': 'DE3',\n",
        "        'E4': 'DE4'\n",
        "    }\n",
        "\n",
        "    for label, new_label in label_mapping.items():\n",
        "        row = df[df['Label'] == label]\n",
        "        x = row['x'].values[0]\n",
        "        y = row['y'].values[0]\n",
        "        distance = calculate_distance(point2_x, point2_y, x, y)\n",
        "        distances[new_label] = distance\n",
        "\n",
        "    # Create a new DataFrame with the results for the current file\n",
        "    file_results = pd.DataFrame([distances], index=[file_name])\n",
        "\n",
        "    # Append the file results to the overall results DataFrame\n",
        "    results = pd.concat([results, file_results])\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results.to_csv('/content/drive/MyDrive/CochlearDistance42/ResNetPreD.csv', float_format='%.2f')"
      ],
      "metadata": {
        "id": "8KFIFuoY_ZBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Conversion Factors from Predicted values and Actual values"
      ],
      "metadata": {
        "id": "RVKmbJV7_H3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the average conversion factors\n",
        "conversion_factors = {\n",
        "    'DL1': 0.009903744900565298,\n",
        "    'DL2': 0.011548086674706151,\n",
        "    'DL3': 0.011543324708090776,\n",
        "    'DL4': 0.009351584017787348,\n",
        "    'DE1': 0.009561528996987883,\n",
        "    'DE2': 0.011767608791001308,\n",
        "    'DE3': 0.0117744825198021,\n",
        "    'DE4': 0.009391603290466594\n",
        "}\n",
        "\n",
        "# Read the CSV file with distance values\n",
        "df = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/ResNetPreD42.csv')\n",
        "\n",
        "# Loop over the columns (distance labels)\n",
        "for column in df.columns[2:]:\n",
        "    # Get the conversion factor for the current label\n",
        "    conversion_factor = conversion_factors[column]\n",
        "\n",
        "    # Convert the distance values to millimeters\n",
        "    df[column] = df[column] * conversion_factor\n",
        "\n",
        "# Save the converted distances to a new CSV file\n",
        "df.to_csv('/content/drive/MyDrive/CochlearDistance42/ResNetPreD_mmX42.csv', index=False, float_format='%.2f')"
      ],
      "metadata": {
        "id": "ybBW7oog-0cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Read the CSV file with the actual distance values in millimeters\n",
        "actual_distances_df = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/CochlearDMM42.csv')\n",
        "\n",
        "# Read the CSV file with the newly generated millimeter values\n",
        "calculated_distances_mm_df = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/ResNetPreD_mmX42.csv')\n",
        "\n",
        "# Get the columns to evaluate\n",
        "columns_to_evaluate = ['DL1', 'DL2', 'DL3', 'DL4', 'DE1', 'DE2', 'DE3', 'DE4']\n",
        "\n",
        "# Calculate the mean absolute error for each column\n",
        "mae_scores = {}\n",
        "for column in columns_to_evaluate:\n",
        "    # Select the first 8 rows from the actual and calculated distances dataframes\n",
        "    actual_distances = actual_distances_df[column][:8]\n",
        "    calculated_distances = calculated_distances_mm_df[column][:8]\n",
        "\n",
        "    # Calculate the mean absolute error\n",
        "    mae = mean_absolute_error(actual_distances, calculated_distances)\n",
        "    mae_scores[column] = mae\n",
        "\n",
        "# Print the mean absolute error for each column\n",
        "for column, mae in mae_scores.items():\n",
        "    print(f\"Mean Absolute Error for {column}: {mae}\")"
      ],
      "metadata": {
        "id": "NRWuP9-o_dKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Mean Absolute Differences of CNN Prediction model"
      ],
      "metadata": {
        "id": "lEFvxDcpPg2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the CNN predicted values dataset from a CSV file\n",
        "calculated_data = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/CNNPreD_mm42.csv')\n",
        "\n",
        "# Load the actual values dataset from a CSV file\n",
        "actual_data = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/CochlearDMM0_8.csv')\n",
        "\n",
        "# Extract the values from the calculated_data DataFrame\n",
        "calculated_values = calculated_data.iloc[:, 1:].values\n",
        "\n",
        "# Extract the values from the actual_data DataFrame\n",
        "actual_values = actual_data.iloc[:, 1:].values\n",
        "\n",
        "# Calculate the absolute differences for each column\n",
        "absolute_diff = np.abs(calculated_values - actual_values)\n",
        "\n",
        "# Calculate the Mean Absolute Difference (MAD) for each column\n",
        "mad_per_column = np.mean(absolute_diff, axis=0)\n",
        "\n",
        "# Calculate the total Mean Absolute Difference (MAD) for all columns combined\n",
        "mad_total = np.mean(absolute_diff)\n",
        "\n",
        "# Display the MAD for each column\n",
        "columns = calculated_data.columns[1:]  # Exclude the first column (image names or identifiers)\n",
        "for column, mad_value in zip(columns, mad_per_column):\n",
        "    print(\"Mean Absolute Difference ({}): {:.6f}\".format(column, mad_value))\n",
        "\n",
        "# Display the total MAD for all columns combined\n",
        "print(\"Total Mean Absolute Difference (All Columns): {:.6f}\".format(mad_total))\n"
      ],
      "metadata": {
        "id": "jG1-vlSaPgH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Mean Absolute Differences of ResNet Prediction model"
      ],
      "metadata": {
        "id": "k49rnwR5PxQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the ResNet predicted values dataset from a CSV file\n",
        "calculated_data = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/ResNetPreD_mmX42.csv')\n",
        "\n",
        "# Load the actual values dataset from a CSV file\n",
        "actual_data = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/CochlearDMM0_8.csv')\n",
        "\n",
        "# Extract the values from the calculated_data DataFrame\n",
        "calculated_values = calculated_data.iloc[:, 1:].values\n",
        "\n",
        "# Extract the values from the actual_data DataFrame\n",
        "actual_values = actual_data.iloc[:, 1:].values\n",
        "\n",
        "# Calculate the absolute differences for each column\n",
        "absolute_diff = np.abs(calculated_values - actual_values)\n",
        "\n",
        "# Calculate the Mean Absolute Difference (MAD) for each column\n",
        "mad_per_column = np.mean(absolute_diff, axis=0)\n",
        "\n",
        "# Calculate the total Mean Absolute Difference (MAD) for all columns combined\n",
        "mad_total = np.mean(absolute_diff)\n",
        "\n",
        "# Display the MAD for each column\n",
        "columns = calculated_data.columns[1:]  # Exclude the first column (image names or identifiers)\n",
        "for column, mad_value in zip(columns, mad_per_column):\n",
        "    print(\"Mean Absolute Difference ({}): {:.6f}\".format(column, mad_value))\n",
        "\n",
        "# Display the total MAD for all columns combined\n",
        "print(\"Total Mean Absolute Difference (All Columns): {:.6f}\".format(mad_total))\n"
      ],
      "metadata": {
        "id": "hg8gVrVePzEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating MAD of CNN and ResNet models and Export results in CSV file"
      ],
      "metadata": {
        "id": "joxHZik0P0-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the CNN predicted values dataset from a CSV file\n",
        "cnn_calculated_data = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/CNNPreD_mm42.csv')\n",
        "\n",
        "# Load the ResNet predicted values dataset from a CSV file\n",
        "resnet_calculated_data = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/ResNetPreD_mmX42.csv')\n",
        "\n",
        "# Load the actual values dataset from a CSV file\n",
        "actual_data = pd.read_csv('/content/drive/MyDrive/CochlearDistance42/CochlearDMM0_8.csv')\n",
        "\n",
        "# Extract the values from the calculated_data DataFrames\n",
        "cnn_calculated_values = cnn_calculated_data.iloc[:, 1:].values\n",
        "resnet_calculated_values = resnet_calculated_data.iloc[:, 1:].values\n",
        "\n",
        "# Extract the values from the actual_data DataFrame\n",
        "actual_values = actual_data.iloc[:, 1:].values\n",
        "\n",
        "# Calculate the absolute differences for each model\n",
        "cnn_absolute_diff = np.abs(cnn_calculated_values - actual_values)\n",
        "resnet_absolute_diff = np.abs(resnet_calculated_values - actual_values)\n",
        "\n",
        "# Calculate the Mean Absolute Difference (MAD) for each model\n",
        "cnn_mad_per_column = np.mean(cnn_absolute_diff, axis=0)\n",
        "resnet_mad_per_column = np.mean(resnet_absolute_diff, axis=0)\n",
        "\n",
        "# Combine the MAD results into a DataFrame\n",
        "mad_results = pd.DataFrame({\n",
        "    'Model': ['CNN', 'ResNet'],\n",
        "    'DL1': [cnn_mad_per_column[0], resnet_mad_per_column[0]],\n",
        "    'DL2': [cnn_mad_per_column[1], resnet_mad_per_column[1]],\n",
        "    'DL3': [cnn_mad_per_column[2], resnet_mad_per_column[2]],\n",
        "    'DL4': [cnn_mad_per_column[3], resnet_mad_per_column[3]],\n",
        "    'DE1': [cnn_mad_per_column[4], resnet_mad_per_column[4]],\n",
        "    'DE2': [cnn_mad_per_column[5], resnet_mad_per_column[5]],\n",
        "    'DE3': [cnn_mad_per_column[6], resnet_mad_per_column[6]],\n",
        "    'DE4': [cnn_mad_per_column[7], resnet_mad_per_column[7]],\n",
        "    'Total MAD': [np.mean(cnn_absolute_diff), np.mean(resnet_absolute_diff)]\n",
        "})\n",
        "\n",
        "# Export the MAD results to a CSV file\n",
        "mad_results.to_csv('/content/drive/MyDrive/CochlearDistance42/MAD_results.csv', index=False)\n"
      ],
      "metadata": {
        "id": "_bMzAi9BQAi3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}